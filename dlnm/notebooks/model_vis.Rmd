---
title: "Slices and model visualization"
author: "Mike O'Brien"
date: "9/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::opts_knit$set(root.dir = 'c:/users/darpa2/analysis/wea-analysis/dlnm')
knitr::opts_knit$set(root.dir = 'p:/obrien/biotelemetry/md wea habitat/wea-analysis/dlnm')
```

## Packages
```{r}
library(dlnm)
library(mgcv)
library(dplyr)
library(ggplot2)
```


## Pull in winning models
Sturgeon model 7 ($\sim f(SSTlag) + f(DOY:Depth)$) and striped bass model 6 ($\sim f(SSTlag) + f(log(CHLA)) + f(DOY:Depth)$) were selected as the best models via AIC.

```{r}
s_mod <- readRDS('sturg_lag_models.RDS')[['SM7']]
b_mod <- readRDS('sb_lag_models.rds')[['BM6']]
```


## Lag plots
### Sturgeon

Using the built-in contour plotting from `dlnm`, we can get something like the below, which I think makes it easier to see what's going on than a 3D plot.

```{r}
plot(crosspred('Qs2', s_mod, cen = 0), ptype = 'contour')
```

Unfortunately, this doesn't give us standard errors unless we switch over to taking slices along a lag...

```{r}
plot(crosspred('Qs2', s_mod, cen = 0),
     ptype = 'slices', lag = c(0, 18))
```

...and the response is always reported in reference to what the predicted outcome at 0 lag was (the `cen = 0` in the code above). We can recreate this using `predict.gam`, allowing us to not use the 0 reference value and get a clearer view of what this is doing to the model.

```{r}
new_data_lag <- expand.grid(
  Qs2 = seq(-7, 10,length.out = 100),
  Ls2 = seq(0, 29, length.out = 100)
)

# assume constant offset for now
new_data_lag$d50.s <- exp(median(s_mod$model$`offset(log(d50.s))`))

preds <- predict(s_mod, new_data_lag, type = 'link',
                    exclude = c('s(Site)', 's(Year)', 'te(DOY,Depth)'),
                    newdata.guaranteed = T)

new_data_lag$pred <- preds
```

To recreate the contour plot above, first plot out the predictions on the link scale.

```{r}
ggplot(data = new_data_lag, aes(x = Qs2, y = Ls2, z = pred)) +
  geom_contour_filled() +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_minimal()
```

These look somewhat similar, but they are almost 4 units less than the predictions reported in the other plot. At a Qs2 (SSTlag) value of 0, it looks like the predictions are around -3. So, lets try to add 3 to the predictions to "center" it around SSTlag = 0.

```{r}
ggplot(data = new_data_lag, aes(x = Qs2, y = Ls2, z = pred + 3)) +
  geom_contour_filled() +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_minimal()
```

Yes, that's pretty darn similar for a shot in the dark. Whereas we chose one centering value and applied it across the plot, I believe that `crosspred` centers each lag individually. Now, what does the contour plot look like on the response scale? Not going to center on 0 here.

```{r}
new_data_lag <- expand.grid(
  Qs2 = seq(-7, 10,length.out = 100),
  Ls2 = seq(0, 29, length.out = 100)
)

# assume constant offset for now
new_data_lag$d50.s <- exp(median(s_mod$model$`offset(log(d50.s))`))

preds <- predict(s_mod, new_data_lag, type = 'response',
                    exclude = c('s(Site)', 's(Year)', 'te(DOY,Depth)'),
                    newdata.guaranteed = T)

new_data_lag$pred <- preds

ggplot(data = new_data_lag, aes(x = Qs2, y = Ls2, z = pred)) +
  geom_contour_filled() +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_minimal()
```

What about the slices at lags of 0 and 18?

```{r}
new_data_lag <- expand.grid(
  Qs2 = seq(-7, 10,length.out = 100),
  Ls2 = c(0, 18)
)

new_data_lag <- data.frame(Qs2 = new_data_lag$Qs2,
                           Ls2 = new_data_lag$Ls2,
                           d50.s = exp(
                             mean(s_mod$model[s_mod$model$DOY == 125,]$`offset(log(d50.s))`)
                           )
)

preds <- predict(s_mod, new_data_lag, type = 'link', se = T,
              exclude = c('s(Site)', 's(Year)', 'te(DOY,Depth)'),
              newdata.guaranteed = T)

new_data_lag$pred <- exp(preds$fit)
new_data_lag$lci <- exp(preds$fit - 1.96 * preds$se.fit)
new_data_lag$uci <- exp(preds$fit + 1.96 * preds$se.fit)


ggplot(data = new_data_lag, aes(x = Qs2, y = pred)) +
  geom_ribbon(aes(ymin = lci, ymax = uci), fill = 'lightgray') +
  geom_line() +
  scale_y_continuous(expand = c(0, 0), limits = c(0, NA)) +
  scale_x_continuous(expand = c(0, 0)) +
  facet_wrap(~Ls2, scales = 'free_y')+
  theme_minimal()
```

5% of one fish predicted? None of that is very engaging. However, this is the marginal (partial? I always forget...) effect on the response of the SST lag smooth, dropping all other variables from the model. So $\sim f(SSTlag) + f(DOY:Depth)$ becomes $\sim f(SSTlag) + 0 * f(DOY:Depth)$ (that explanation is likely incorrect, but that's how I see it in my non-statistician mind). What if we focus on the effect of $f(SSTlag)$ at different levels of $f(DOY:Depth)$? Basically, adjusting the "intercept" up and down according to the outcome of $f(DOY:Depth)$. What would an interesting combination of DOY and depth be? I've highlighted two below:

```{r}
plot(s_mod, select = 4)
points(125, 16, col = 'blue', pch = 19, cex = 2)
points(280, 29, col = 'blue', pch = 19, cex = 2)
```

Okay, so it looks like a depth of 16m on day 125 (May 4) and a depth of 29m on day 280 (Oct 6) are predicted sturgeon hot spots. How does the predicted number of sturgeon respond on those days/depths?

```{r}
new_data_lag <- expand.grid(
  Qs2 = seq(-7, 10,length.out = 100),
  Ls2 = seq(0, 29, length.out = 100)
)
new_data_lag <- data.frame(Qs2 = rep(new_data_lag$Qs2, times = 2),
                           Ls2 = rep(new_data_lag$Ls2, times = 2),
                           DOY = rep(c(125, 280), times = nrow(new_data_lag)),
                           Depth = rep(c(16, 29), times = nrow(new_data_lag)),
                           d50.s = exp(
                             mean(s_mod$model[s_mod$model$DOY == 125,]$`offset(log(d50.s))`)
                           )
)


preds <- predict(s_mod, new_data_lag, type = 'response',
              exclude = c('s(Site)', 's(Year)'),
              newdata.guaranteed = T)

new_data_lag$pred <- preds

ggplot(data = new_data_lag, aes(x = Qs2, y = Ls2, z = pred)) +
  geom_contour_filled(breaks = c(seq(0, 10, 1), Inf)) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  facet_wrap(~interaction(DOY, Depth)) +
  theme_minimal()
```

That's a lot of sturgeon in the edge case of lag = 0, $SSTlag \approx$ 10 (remember that the maximum number of recorded sturgeon was 5). Let's look across the lags of 0 and 18 again. Note that the predictions reported on the link scale are the natural log of those on the response scale, so we'll take their exponent.

```{r}
new_data_lag <- expand.grid(
  Qs2 = seq(-7, 10,length.out = 100),
  Ls2 = c(0, 18)
)

new_data_lag <- data.frame(Qs2 = rep(new_data_lag$Qs2, times = 2),
                           Ls2 = rep(new_data_lag$Ls2, times = 2),
                           DOY = rep(c(125, 280), times = nrow(new_data_lag)),
                           Depth = rep(c(16, 29), times = nrow(new_data_lag)),
                           d50.s = exp(
                             mean(s_mod$model[s_mod$model$DOY == 125,]$`offset(log(d50.s))`)
                           )
)

preds <- predict(s_mod, new_data_lag, type = 'link', se = T,
              exclude = c('s(Site)', 's(Year)'),
              newdata.guaranteed = T)

new_data_lag$pred <- exp(preds$fit)
new_data_lag$lci <- exp(preds$fit - 1.96 * preds$se.fit)
new_data_lag$uci <- exp(preds$fit + 1.96 * preds$se.fit)


ggplot(data = new_data_lag, aes(x = Qs2, y = pred)) +
  geom_ribbon(aes(ymin = lci, ymax = uci), fill = 'lightgray') +
  geom_line() +
  scale_y_continuous(expand = c(0, 0), limits = c(0, NA)) +
  scale_x_continuous(expand = c(0, 0)) +
  facet_grid(Ls2 ~ interaction(DOY, Depth), scales = 'free_y')+
  theme_minimal()
```

Eesh, that first CI is wild. Let's zoom in.

```{r}
ggplot(data = new_data_lag[new_data_lag$Ls2 == 0,], aes(x = Qs2, y = pred)) +
  geom_ribbon(aes(ymin = lci, ymax = uci), fill = 'lightgray') +
  geom_line() +
  coord_cartesian(ylim = c(0, 30)) +
  scale_x_continuous(expand = c(0,0)) +
  facet_wrap(~ interaction(DOY, Depth), nrow = 1) +
  theme_minimal()
```

We're still definitely predicting the presence of sturgeon, but we should be cautious at $SSTlag$ > 5ish since it quickly starts to report way more sturgeon that we recorded.




### Striped bass
```{r}
plot(crosspred('Qb2', b_mod, cen = 0), ptype = 'contour')
```
